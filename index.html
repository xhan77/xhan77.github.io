<!DOCTYPE html>

<html>
<head>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.2/css/bootstrap.min.css" integrity="sha384-Smlep5jCw/wG7hdkwQ/Z5nLIefveQRIY9nfy6xoR1uRYBtpZgI6339F5dgvm/e9B" crossorigin="anonymous">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="stylesheet" href="css/style.css" type="text/css" />
	<title>Xiaochuang Han</title>
</head>

<body>

<div class="container-fluid w-50">
    <div class="row top-buffer vertical-align">
      <div class="col-8">
        <table border="0">
        <tr>
        <td><font size="6"><b>Xiaochuang Han</b>&nbsp;&nbsp;</font></td>
        <td><img align=right src="img/my_name_pic.png" height=60></td>
        </tr>
        </table>
        <p><font size="2">(You can call me <b>Han</b>, which is easier to pronounce and remember)</font></p>
        <p><font face="courier">firstname.lastname@gmail.com</font></p>
        <p>
        [<a href="docs/Han_CV_240913.pdf">CV</a>]
        [<a href="https://scholar.google.com/citations?user=GamSVF0AAAAJ&hl=en"><font size="3">Google Scholar</font></a>]
        </p>
        <br>
      </div>
      <div class="col-4">
        <img src="img/my_pic.jpg" style="width:100%">
      </div>
    </div>

    <hr>

    <div class="row top-buffer vertical-align">
        <div class="col">
            <div class="section_title"><p><b>Bio</b></p></div>
            <p>
            I'm a PhD student in Computer Science and Engineering at the University of Washington, advised by <a href=https://homes.cs.washington.edu/~yuliats/>Yulia Tsvetkov</a>. I'm generally interested in natural language processing and multimodal generation. I have worked on topics like codec-based multimodal generation, diffusion language models, inference-time model collaboration, training data attribution, etc. Before UW, I was a Master of Language Technologies student at Carnegie Mellon University. Before CMU, I was an undergrad at Georgia Tech, advised by <a href=https://jacobeisenstein.github.io/>Jacob Eisenstein</a>. I have been supported by OpenAI Superalignment Fellowship (2024) and Meta AI Mentorship Program (2023, 2022).
            </p>
            <!-- <p><b>
            Starting from Fall 2021, I will be a PhD student in computer science and engineering at the University of Washington, working with <a href=https://www.cs.cmu.edu/~ytsvetko/>Yulia Tsvetkov</a>.
            </b></p> -->
        </div>
    </div>
    <hr>

    <div class="row top-buffer vertical-align">
        <div class="col">
            <div class="section_title"><p><b>Selected Publications</b></p></div>

		Please see my Google Scholar or CV for a full list of publications. <br>
		<br>
            <a href="https://arxiv.org/abs/2408.08459">JPEG-LM: LLMs as Image Generators with Canonical Codec Representations</a><br>
            <span class="author"><b>Xiaochuang Han</b></span>, <span class="author">Marjan Ghazvininejad</span>, <span class="author">Pang Wei Koh</span>, and <span class="author">Yulia Tsvetkov</span>.<br>
            <i>arXiv preprint</i><br>
            <br>
		
            <a href="https://arxiv.org/abs/2305.14771">David helps Goliath: Inference-Time Collaboration Between Small Specialized and Large General Diffusion LMs</a><br>
            <span class="author"><b>Xiaochuang Han</b></span>, <span class="author">Sachin Kumar</span>, <span class="author">Yulia Tsvetkov</span>, and <span class="author">Marjan Ghazvininejad</span>.<br>
            <i>NAACL 2024</i><br>
            <br>

            <a href="https://arxiv.org/abs/2401.08565">Tuning Language Models by Proxy</a><br>
            <span class="author">Alisa Liu</span>, <span class="author"><b>Xiaochuang Han</b></span>, <span class="author">Yizhong Wang</span>, <span class="author">Yulia Tsvetkov</span>, <span class="author">Yejin Choi</span>, <span class="author">Noah Smith</span>.<br>
            <i>COLM 2024</i><br>
            <br>
		
            <a href="https://arxiv.org/abs/2305.14739">Trusting Your Evidence: Hallucinate Less with Context-aware Decoding</a><br>
            <span class="author">Weijia Shi*</span>, <span class="author"><b>Xiaochuang Han*</b></span>, <span class="author">Mike Lewis</span>, <span class="author">Yulia Tsvetkov</span>, <span class="author">Luke Zettlemoyer</span>, and <span class="author">Scott Wen-tau Yih</span>.<br>
            <i>NAACL 2024</i><br>
            <br>
		
            <a href="https://arxiv.org/abs/2308.04275">In-Context Alignment: Chat with Vanilla Language Models Before Fine-Tuning</a><br>
            <span class="author"><b>Xiaochuang Han</b></span>.<br>
            <i>arXiv preprint</i><br>
            <br>

            <a href="https://arxiv.org/abs/2210.17432">SSD-LM: Semi-autoregressive Simplex-based Diffusion Language Model for Text Generation and Modular Control</a><br>
            <span class="author"><b>Xiaochuang Han</b></span>, <span class="author">Sachin Kumar</span>, and <span class="author">Yulia Tsvetkov</span>.<br>
            <i>ACL 2023</i><br>
            <br>

            <a href="https://arxiv.org/abs/2306.15091">Understanding In-Context Learning via Supportive Pretraining Data</a><br>
            <span class="author"><b>Xiaochuang Han</b></span>, <span class="author">Daniel Simig</span>, <span class="author">Todor Mihaylov</span>, <span class="author">Yulia Tsvetkov</span>, <span class="author">Asli Celikyilmaz</span>, and <span class="author">Tianlu Wang</span>.<br>
            <i>ACL 2023</i><br>
            <br>

            <a href="https://arxiv.org/abs/2212.10539">Toward Human Readable Prompt Tuning: Kubrick's The Shining is a good movie, and a good prompt too?</a><br>
            <span class="author">Weijia Shi*</span>, <span class="author"><b>Xiaochuang Han*</b></span>, <span class="author">Hila Gonen</span>, <span class="author">Ari Holtzman</span>, <span class="author">Yulia Tsvetkov</span>, and <span class="author">Luke Zettlemoyer</span>.<br>
            <i>Findings of EMNLP 2023</i><br>
            <br>

            <a href="https://arxiv.org/abs/2205.12600">ORCA: Interpreting Prompted Language Models via Locating Supporting Data Evidence in the Ocean of Pretraining Data</a><br>
            <span class="author"><b>Xiaochuang Han</b></span> and <span class="author">Yulia Tsvetkov</span>.<br>
            <i>arXiv preprint</i><br>
            <br>
		
            <a href="https://arxiv.org/abs/2110.03212">Influence Tuning: Demoting Spurious Correlations via Instance Attribution and Instance-Driven Updates</a><br>
            <span class="author"><b>Xiaochuang Han</b></span> and <span class="author">Yulia Tsvetkov</span>.<br>
            <i>Findings of EMNLP 2021</i><br>
            <br>

            <a href="https://arxiv.org/abs/2010.03154">Fortifying Toxic Speech Detectors Against Veiled Toxicity</a><br>
            <span class="author"><b>Xiaochuang Han</b></span> and <span class="author">Yulia Tsvetkov</span>.<br>
            <i>EMNLP 2020</i><br>
            <br>

            <a href="https://arxiv.org/abs/2005.06676">Explaining Black Box Predictions and Unveiling Data Artifacts through Influence Functions</a><br>
            <span class="author"><b>Xiaochuang Han</b></span>, <span class="author">Byron C. Wallace</span>, and <span class="author">Yulia Tsvetkov</span>.<br>
            <i>ACL 2020</i><br>
            <br>

            <a href="https://arxiv.org/abs/1904.02817">Unsupervised Domain Adaptation of Contextualized Embeddings for Sequence Labeling</a><br>
            <span class="author"><b>Xiaochuang Han</b></span> and <span class="author">Jacob Eisenstein</span>.<br>
            <i>EMNLP 2019</i><br>
            <br>

            <a href="https://arxiv.org/abs/1904.08950">No Permanent Friends or Enemies: Tracking Dynamic Relationships between Nations from News</a><br>
            <span class="author"><b>Xiaochuang Han</b></span>, <span class="author">Eunsol Choi</span>, and <span class="author">Chenhao Tan</span>.<br>
            <i>NAACL 2019</i><br>
            <br>

            <a href="https://arxiv.org/abs/1809.06951">Mind Your POV: Convergence of Articles and Editors Towards Wikipedia's Neutrality Norm</a><br>
            <span class="author">Umashanthi Pavalanathan</span>, <span class="author"><b>Xiaochuang Han</b></span>, and <span class="author">Jacob Eisenstein</span>.<br>
            <i>CSCW 2018</i><br>
            <br>

            <br>
        </div>
    </div>

</div>

</body>
